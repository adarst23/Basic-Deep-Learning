{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b3ed0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0320840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98550f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb9676e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9aecba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7606b462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98682db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2f100b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e121c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber','CustomerId','Surname'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "286db0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5944a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0                  1        101348.88       1                  0   \n",
       "1                  1        112542.58       0                  0   \n",
       "2                  0        113931.57       1                  0   \n",
       "3                  0         93826.63       0                  0   \n",
       "4                  1         79084.10       0                  0   \n",
       "...              ...              ...     ...                ...   \n",
       "9995               0         96270.64       0                  0   \n",
       "9996               1        101699.77       0                  0   \n",
       "9997               1         42085.58       1                  0   \n",
       "9998               0         92888.52       1                  1   \n",
       "9999               0         38190.78       0                  0   \n",
       "\n",
       "      Geography_Spain  Gender_Male  \n",
       "0                   0            0  \n",
       "1                   1            0  \n",
       "2                   0            0  \n",
       "3                   0            0  \n",
       "4                   1            0  \n",
       "...               ...          ...  \n",
       "9995                0            1  \n",
       "9996                0            1  \n",
       "9997                0            0  \n",
       "9998                0            1  \n",
       "9999                0            0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df,columns=['Geography','Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca31dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df,columns=['Geography','Gender'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b3c9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae1c3cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ec94fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited',axis=1)\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82a403a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d28b1e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd9b733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "151ad9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ead388eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "212efd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35649971, -0.6557859 ,  0.34567966, ..., -0.57946723,\n",
       "        -0.57638802,  0.91324755],\n",
       "       [-0.20389777,  0.29493847, -0.3483691 , ...,  1.72572313,\n",
       "        -0.57638802,  0.91324755],\n",
       "       [-0.96147213, -1.41636539, -0.69539349, ..., -0.57946723,\n",
       "         1.73494238,  0.91324755],\n",
       "       ...,\n",
       "       [ 0.86500853, -0.08535128, -1.38944225, ..., -0.57946723,\n",
       "        -0.57638802, -1.09499335],\n",
       "       [ 0.15932282,  0.3900109 ,  1.03972843, ..., -0.57946723,\n",
       "        -0.57638802,  0.91324755],\n",
       "       [ 0.47065475,  1.15059039, -1.38944225, ...,  1.72572313,\n",
       "        -0.57638802,  0.91324755]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a553082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "756edfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(11,activation='relu', input_dim=11))\n",
    "model.add(Dense(11,activation='relu'))\n",
    "model.add(Dense(9,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d35fef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 9)                 108       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 382 (1.49 KB)\n",
      "Trainable params: 382 (1.49 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5a524e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c184f842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 679.2551 - accuracy: 0.6195 - val_loss: 1.8661 - val_accuracy: 0.7950\n",
      "Epoch 2/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.2532 - accuracy: 0.7928 - val_loss: 0.6205 - val_accuracy: 0.7969\n",
      "Epoch 3/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.7934 - val_loss: 0.5827 - val_accuracy: 0.7975\n",
      "Epoch 4/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.7930 - val_loss: 0.5603 - val_accuracy: 0.7969\n",
      "Epoch 5/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7934 - val_loss: 0.5407 - val_accuracy: 0.7975\n",
      "Epoch 6/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7934 - val_loss: 0.5301 - val_accuracy: 0.7969\n",
      "Epoch 7/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7934 - val_loss: 0.5198 - val_accuracy: 0.7975\n",
      "Epoch 8/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7981\n",
      "Epoch 9/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7934 - val_loss: 0.5104 - val_accuracy: 0.7969\n",
      "Epoch 10/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7934 - val_loss: 0.5065 - val_accuracy: 0.7987\n",
      "Epoch 11/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
      "Epoch 12/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7934 - val_loss: 0.5087 - val_accuracy: 0.7969\n",
      "Epoch 13/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7933 - val_loss: 0.5046 - val_accuracy: 0.7969\n",
      "Epoch 14/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7975\n",
      "Epoch 15/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7975\n",
      "Epoch 16/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7987\n",
      "Epoch 17/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7987\n",
      "Epoch 18/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
      "Epoch 19/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7969\n",
      "Epoch 20/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
      "Epoch 21/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7975\n",
      "Epoch 22/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7987\n",
      "Epoch 23/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7933 - val_loss: 0.5022 - val_accuracy: 0.7987\n",
      "Epoch 24/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7969\n",
      "Epoch 25/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7933 - val_loss: 0.5035 - val_accuracy: 0.7969\n",
      "Epoch 26/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7933 - val_loss: 0.5036 - val_accuracy: 0.7969\n",
      "Epoch 27/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7936 - val_loss: 0.5123 - val_accuracy: 0.7962\n",
      "Epoch 28/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7931 - val_loss: 0.5019 - val_accuracy: 0.7987\n",
      "Epoch 29/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7987\n",
      "Epoch 30/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 31/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7934 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
      "Epoch 32/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7931 - val_loss: 0.5021 - val_accuracy: 0.7981\n",
      "Epoch 33/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7987\n",
      "Epoch 34/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5016 - val_accuracy: 0.7987\n",
      "Epoch 35/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7981\n",
      "Epoch 36/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7975\n",
      "Epoch 37/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7934 - val_loss: 0.5063 - val_accuracy: 0.7969\n",
      "Epoch 38/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7975\n",
      "Epoch 39/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7975\n",
      "Epoch 40/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7975\n",
      "Epoch 41/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7936 - val_loss: 0.5048 - val_accuracy: 0.7969\n",
      "Epoch 42/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7933 - val_loss: 0.5035 - val_accuracy: 0.7969\n",
      "Epoch 43/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7931 - val_loss: 0.5026 - val_accuracy: 0.7975\n",
      "Epoch 44/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7933 - val_loss: 0.5017 - val_accuracy: 0.7987\n",
      "Epoch 45/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5026 - val_accuracy: 0.7975\n",
      "Epoch 46/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7936 - val_loss: 0.5031 - val_accuracy: 0.7969\n",
      "Epoch 47/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5045 - val_accuracy: 0.7969\n",
      "Epoch 48/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7936 - val_loss: 0.5030 - val_accuracy: 0.7969\n",
      "Epoch 49/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5049 - val_accuracy: 0.7969\n",
      "Epoch 50/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 51/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7936 - val_loss: 0.5097 - val_accuracy: 0.7962\n",
      "Epoch 52/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5089 - val_accuracy: 0.7962\n",
      "Epoch 53/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5076 - val_accuracy: 0.7962\n",
      "Epoch 54/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5065 - val_accuracy: 0.7969\n",
      "Epoch 55/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
      "Epoch 56/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
      "Epoch 57/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5061 - val_accuracy: 0.7969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5056 - val_accuracy: 0.7969\n",
      "Epoch 59/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
      "Epoch 60/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5059 - val_accuracy: 0.7969\n",
      "Epoch 61/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5058 - val_accuracy: 0.7969\n",
      "Epoch 62/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5053 - val_accuracy: 0.7969\n",
      "Epoch 63/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5061 - val_accuracy: 0.7969\n",
      "Epoch 64/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5067 - val_accuracy: 0.7969\n",
      "Epoch 65/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5080 - val_accuracy: 0.7969\n",
      "Epoch 66/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5060 - val_accuracy: 0.7975\n",
      "Epoch 67/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5066 - val_accuracy: 0.7969\n",
      "Epoch 68/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5051 - val_accuracy: 0.7975\n",
      "Epoch 69/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5097 - val_accuracy: 0.7962\n",
      "Epoch 70/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5088 - val_accuracy: 0.7969\n",
      "Epoch 71/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5069 - val_accuracy: 0.7975\n",
      "Epoch 72/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5095 - val_accuracy: 0.7962\n",
      "Epoch 73/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5053 - val_accuracy: 0.7975\n",
      "Epoch 74/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7934 - val_loss: 0.5090 - val_accuracy: 0.7962\n",
      "Epoch 75/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7936 - val_loss: 0.5074 - val_accuracy: 0.7969\n",
      "Epoch 76/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5053 - val_accuracy: 0.7981\n",
      "Epoch 77/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5062 - val_accuracy: 0.7969\n",
      "Epoch 78/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7936 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 79/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5055 - val_accuracy: 0.7975\n",
      "Epoch 80/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5069 - val_accuracy: 0.7969\n",
      "Epoch 81/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5055 - val_accuracy: 0.7975\n",
      "Epoch 82/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5074 - val_accuracy: 0.7962\n",
      "Epoch 83/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5050 - val_accuracy: 0.7981\n",
      "Epoch 84/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7936 - val_loss: 0.5055 - val_accuracy: 0.7981\n",
      "Epoch 85/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5070 - val_accuracy: 0.7975\n",
      "Epoch 86/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5110 - val_accuracy: 0.7962\n",
      "Epoch 87/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7936 - val_loss: 0.5114 - val_accuracy: 0.7962\n",
      "Epoch 88/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7936 - val_loss: 0.5144 - val_accuracy: 0.7962\n",
      "Epoch 89/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7933 - val_loss: 0.5047 - val_accuracy: 0.7975\n",
      "Epoch 90/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5047 - val_accuracy: 0.7975\n",
      "Epoch 91/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7975\n",
      "Epoch 92/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5046 - val_accuracy: 0.7975\n",
      "Epoch 93/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7975\n",
      "Epoch 94/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5045 - val_accuracy: 0.7975\n",
      "Epoch 95/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7975\n",
      "Epoch 96/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5044 - val_accuracy: 0.7975\n",
      "Epoch 97/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7975\n",
      "Epoch 98/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5043 - val_accuracy: 0.7975\n",
      "Epoch 99/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5042 - val_accuracy: 0.7975\n",
      "Epoch 100/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5042 - val_accuracy: 0.7975\n",
      "Epoch 101/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7975\n",
      "Epoch 102/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7975\n",
      "Epoch 103/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5041 - val_accuracy: 0.7975\n",
      "Epoch 104/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7975\n",
      "Epoch 105/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5040 - val_accuracy: 0.7975\n",
      "Epoch 106/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7975\n",
      "Epoch 107/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5039 - val_accuracy: 0.7975\n",
      "Epoch 108/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7975\n",
      "Epoch 109/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5038 - val_accuracy: 0.7975\n",
      "Epoch 110/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7981\n",
      "Epoch 111/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7981\n",
      "Epoch 112/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7981\n",
      "Epoch 113/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5037 - val_accuracy: 0.7981\n",
      "Epoch 114/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7981\n",
      "Epoch 116/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5036 - val_accuracy: 0.7981\n",
      "Epoch 117/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7981\n",
      "Epoch 118/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7981\n",
      "Epoch 119/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7981\n",
      "Epoch 120/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7981\n",
      "Epoch 121/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7981\n",
      "Epoch 122/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 123/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5035 - val_accuracy: 0.7981\n",
      "Epoch 124/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 125/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 126/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 127/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 128/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 129/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 130/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 131/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 132/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 133/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 134/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 135/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 136/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 137/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 138/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 139/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 140/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7981\n",
      "Epoch 141/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 142/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5034 - val_accuracy: 0.7981\n",
      "Epoch 143/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7981\n",
      "Epoch 144/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7981\n",
      "Epoch 145/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5033 - val_accuracy: 0.7981\n",
      "Epoch 146/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7981\n",
      "Epoch 147/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5032 - val_accuracy: 0.7981\n",
      "Epoch 148/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7981\n",
      "Epoch 149/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7981\n",
      "Epoch 150/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7981\n",
      "Epoch 151/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7981\n",
      "Epoch 152/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7981\n",
      "Epoch 153/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7981\n",
      "Epoch 154/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5030 - val_accuracy: 0.7981\n",
      "Epoch 155/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7981\n",
      "Epoch 156/200\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7981\n",
      "Epoch 157/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7981\n",
      "Epoch 158/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7981\n",
      "Epoch 159/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7981\n",
      "Epoch 160/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5029 - val_accuracy: 0.7981\n",
      "Epoch 161/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7981\n",
      "Epoch 162/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7981\n",
      "Epoch 163/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7981\n",
      "Epoch 164/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5028 - val_accuracy: 0.7981\n",
      "Epoch 165/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7981\n",
      "Epoch 166/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7981\n",
      "Epoch 167/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7981\n",
      "Epoch 168/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5027 - val_accuracy: 0.7981\n",
      "Epoch 169/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7981\n",
      "Epoch 170/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7981\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7981\n",
      "Epoch 172/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7981\n",
      "Epoch 173/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7981\n",
      "Epoch 174/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7981\n",
      "Epoch 175/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7981\n",
      "Epoch 176/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7981\n",
      "Epoch 177/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7981\n",
      "Epoch 178/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5025 - val_accuracy: 0.7981\n",
      "Epoch 179/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7981\n",
      "Epoch 180/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7981\n",
      "Epoch 181/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7981\n",
      "Epoch 182/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7981\n",
      "Epoch 183/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7981\n",
      "Epoch 184/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7981\n",
      "Epoch 185/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5023 - val_accuracy: 0.7981\n",
      "Epoch 186/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7981\n",
      "Epoch 187/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7981\n",
      "Epoch 188/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5022 - val_accuracy: 0.7981\n",
      "Epoch 189/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7981\n",
      "Epoch 190/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7981\n",
      "Epoch 191/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7981\n",
      "Epoch 192/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7987\n",
      "Epoch 193/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5021 - val_accuracy: 0.7987\n",
      "Epoch 194/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 195/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 196/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 197/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 198/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 199/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n",
      "Epoch 200/200\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7934 - val_loss: 0.5020 - val_accuracy: 0.7987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=200, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ac2d1f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04357105,  0.06935789, -0.04793604, -0.30008444, -0.04637451,\n",
       "         -0.07785028,  0.13080655,  0.32187653,  0.3781558 ,  0.5224097 ,\n",
       "          0.25435364],\n",
       "        [-0.14927197, -0.16477615,  0.26588833, -0.3534338 ,  0.25815046,\n",
       "         -0.39300823,  0.02024487,  0.4116395 ,  0.07692131, -0.08955732,\n",
       "         -0.65569407],\n",
       "        [ 0.2593249 , -0.11915375,  0.30839854, -0.38547164, -0.08210648,\n",
       "         -0.46507   ,  0.4213426 , -0.10675867,  0.37833   ,  0.11567666,\n",
       "         -0.5125144 ],\n",
       "        [-0.277309  , -0.06923119, -0.31051317,  0.19911206,  0.28394294,\n",
       "         -0.02162242,  0.29729864,  0.35750702, -0.20082045, -0.33670628,\n",
       "         -0.19168493],\n",
       "        [-0.14259636, -0.42973807, -0.52446395, -0.05510976,  0.23519556,\n",
       "          0.02958792, -0.41905257,  0.46664917,  0.23076661, -0.25568116,\n",
       "         -0.40807873],\n",
       "        [ 0.39561993,  0.4565141 , -0.31268427, -0.00232973, -0.11568303,\n",
       "          0.41402203,  0.05588972, -0.16737965,  0.3820235 , -0.4333568 ,\n",
       "         -0.56879455],\n",
       "        [ 0.51014537,  0.04240869,  0.41835785, -0.05955125, -0.03773944,\n",
       "         -0.06035897,  0.42793867,  0.31800994,  0.37157702, -0.18539865,\n",
       "          0.26023313],\n",
       "        [-0.51225287,  0.17026474,  0.04327789, -0.14627777,  0.47445777,\n",
       "         -0.24140817, -0.5463589 ,  0.36865497,  0.45285058, -0.19977772,\n",
       "          0.49249223],\n",
       "        [-0.5009853 ,  0.08490466,  0.3881039 , -0.4384135 , -0.40621987,\n",
       "          0.10560906,  0.09871779, -0.26298812,  0.35452488, -0.09416395,\n",
       "         -0.07913233],\n",
       "        [ 0.17786759, -0.26192585, -0.28880414, -0.42329684, -0.18608393,\n",
       "         -0.5160926 ,  0.17891745,  0.202866  , -0.38408178, -0.17174612,\n",
       "          0.39213273],\n",
       "        [ 0.1944583 , -0.08048446, -0.5102956 ,  0.11444859, -0.28932577,\n",
       "         -0.08710051, -0.5293881 ,  0.57260597, -0.38919467, -0.28095913,\n",
       "         -0.6208512 ]], dtype=float32),\n",
       " array([ 0.        , -0.02490131, -0.20232831, -0.01213819,  0.18578455,\n",
       "         0.        , -0.07765763, -0.06749745, -0.04696304,  0.02166249,\n",
       "        -0.13522205], dtype=float32)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73b09fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.28051513, -0.1846368 , -0.5001893 ,  0.042826  , -0.02227286,\n",
       "          0.2745933 ,  0.16434675,  0.3623675 , -0.09198415,  0.08962679,\n",
       "         -0.19375193],\n",
       "        [-0.4079122 , -0.48733163,  0.3708109 ,  0.06330013,  0.11573107,\n",
       "          0.24077898,  0.10804987, -0.36961251, -0.08679852, -0.33685517,\n",
       "         -0.15986452],\n",
       "        [-0.5219564 ,  0.03872253, -0.04298212, -0.34299654, -0.05921973,\n",
       "          0.33492666,  0.20369256, -0.5007292 , -0.19752383,  0.32253706,\n",
       "         -0.26242986],\n",
       "        [ 0.03483404,  0.41961852, -0.2846121 , -0.19385317,  0.09335392,\n",
       "         -0.43359002, -0.23865512, -0.43878332,  0.44633585,  0.38401145,\n",
       "          0.22204103],\n",
       "        [-0.1444699 , -0.35117003, -0.16614473, -0.23082095,  0.22697997,\n",
       "         -0.06296858, -0.35118875, -0.20556852, -0.4061831 ,  0.02030421,\n",
       "          0.4618401 ],\n",
       "        [ 0.51569766,  0.49398917, -0.090471  , -0.43945444,  0.05665368,\n",
       "         -0.29746866,  0.4240278 , -0.06191248,  0.2747308 , -0.4521216 ,\n",
       "          0.13984579],\n",
       "        [ 0.43256178, -0.41564175, -0.50698274,  0.2864157 ,  0.01398957,\n",
       "         -0.39123172,  0.45657182, -0.17893994,  0.44640753,  0.04746316,\n",
       "         -0.24353126],\n",
       "        [-0.31966484,  0.34182006,  0.34865966, -0.35425186,  0.33091384,\n",
       "         -0.08511493, -0.23176113,  0.31029382,  0.24941847,  0.2677421 ,\n",
       "          0.2023504 ],\n",
       "        [ 0.16153944,  0.05874005,  0.25792256, -0.29095483,  0.18291019,\n",
       "         -0.47828713, -0.16580494, -0.34687337,  0.04826567,  0.35903874,\n",
       "          0.1763113 ],\n",
       "        [ 0.00908899,  0.21934985, -0.2020577 , -0.11651313, -0.19488089,\n",
       "         -0.06155354,  0.5090093 , -0.40091085, -0.3731323 ,  0.0547206 ,\n",
       "          0.5590264 ],\n",
       "        [ 0.11582124,  0.30095008, -0.35590035, -0.24066135, -0.39583024,\n",
       "         -0.09623718,  0.3490479 ,  0.25118527, -0.46251845, -0.1805257 ,\n",
       "         -0.36178145]], dtype=float32),\n",
       " array([-0.02116711, -0.16051245, -0.07779115,  0.        , -0.00115469,\n",
       "         0.        ,  0.00872559, -0.02464871, -0.06974262, -0.10861174,\n",
       "         0.19776008], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4eb7bdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e414938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.where(pred > 0.5,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4043247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "02b650d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8035"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71f96196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a045cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [679.255126953125,\n",
       "  1.253244161605835,\n",
       "  0.6100001931190491,\n",
       "  0.5771929621696472,\n",
       "  0.5522408485412598,\n",
       "  0.5380106568336487,\n",
       "  0.5277400016784668,\n",
       "  0.5208693146705627,\n",
       "  0.5162742733955383,\n",
       "  0.5133304595947266,\n",
       "  0.5115413665771484,\n",
       "  0.5104833245277405,\n",
       "  0.5100343823432922,\n",
       "  0.5094786286354065,\n",
       "  0.5092007517814636,\n",
       "  0.5091445446014404,\n",
       "  0.5091535449028015,\n",
       "  0.5091016888618469,\n",
       "  0.5090527534484863,\n",
       "  0.5090928673744202,\n",
       "  0.5089921355247498,\n",
       "  0.5090306401252747,\n",
       "  0.5091032981872559,\n",
       "  0.5091309547424316,\n",
       "  0.5089980363845825,\n",
       "  0.5091820359230042,\n",
       "  0.5091297030448914,\n",
       "  0.5095385313034058,\n",
       "  0.5090330243110657,\n",
       "  0.5089578628540039,\n",
       "  0.5088948607444763,\n",
       "  0.5091642737388611,\n",
       "  0.5091139674186707,\n",
       "  0.5090967416763306,\n",
       "  0.5091332793235779,\n",
       "  0.5090909004211426,\n",
       "  0.5088579058647156,\n",
       "  0.5092983841896057,\n",
       "  0.5090582370758057,\n",
       "  0.5090023279190063,\n",
       "  0.5090779662132263,\n",
       "  0.5090318918228149,\n",
       "  0.5103188157081604,\n",
       "  0.5089662671089172,\n",
       "  0.5090059638023376,\n",
       "  0.5089280605316162,\n",
       "  0.5089651346206665,\n",
       "  0.5088746547698975,\n",
       "  0.5090046525001526,\n",
       "  0.508885383605957,\n",
       "  0.5451191067695618,\n",
       "  0.5091065764427185,\n",
       "  0.5091263055801392,\n",
       "  0.5090599060058594,\n",
       "  0.5090171694755554,\n",
       "  0.5090318918228149,\n",
       "  0.5090144872665405,\n",
       "  0.5090177655220032,\n",
       "  0.5089991092681885,\n",
       "  0.5090288519859314,\n",
       "  0.5090287327766418,\n",
       "  0.5090002417564392,\n",
       "  0.509028434753418,\n",
       "  0.5090265274047852,\n",
       "  0.5090280771255493,\n",
       "  0.5090283751487732,\n",
       "  0.5090348720550537,\n",
       "  0.5090286731719971,\n",
       "  0.5090299844741821,\n",
       "  0.5090389251708984,\n",
       "  0.5089930891990662,\n",
       "  0.5090207457542419,\n",
       "  0.5090324282646179,\n",
       "  0.5091224908828735,\n",
       "  0.509135365486145,\n",
       "  0.5089911818504333,\n",
       "  0.5090285539627075,\n",
       "  0.50905442237854,\n",
       "  0.509205162525177,\n",
       "  0.5090079307556152,\n",
       "  0.5089811682701111,\n",
       "  0.509020209312439,\n",
       "  0.5089853405952454,\n",
       "  0.5090535879135132,\n",
       "  0.5090022087097168,\n",
       "  0.5089752078056335,\n",
       "  0.5089842081069946,\n",
       "  0.5090816020965576,\n",
       "  0.5094638466835022,\n",
       "  0.5092228055000305,\n",
       "  0.5092162489891052,\n",
       "  0.5092151761054993,\n",
       "  0.5092219710350037,\n",
       "  0.5092116594314575,\n",
       "  0.5092113018035889,\n",
       "  0.5092118382453918,\n",
       "  0.5092272758483887,\n",
       "  0.5092045068740845,\n",
       "  0.5092034339904785,\n",
       "  0.5092147588729858,\n",
       "  0.509227454662323,\n",
       "  0.5092382431030273,\n",
       "  0.5092275142669678,\n",
       "  0.5092033743858337,\n",
       "  0.5092014074325562,\n",
       "  0.5092126727104187,\n",
       "  0.5092206001281738,\n",
       "  0.5092154145240784,\n",
       "  0.5092092752456665,\n",
       "  0.5092206597328186,\n",
       "  0.509233295917511,\n",
       "  0.5092165470123291,\n",
       "  0.5092170834541321,\n",
       "  0.509213387966156,\n",
       "  0.5092102289199829,\n",
       "  0.5092290043830872,\n",
       "  0.5092241168022156,\n",
       "  0.5092178583145142,\n",
       "  0.5092054009437561,\n",
       "  0.5092179775238037,\n",
       "  0.5092201828956604,\n",
       "  0.509213387966156,\n",
       "  0.5092238187789917,\n",
       "  0.509218692779541,\n",
       "  0.5092104077339172,\n",
       "  0.5092113018035889,\n",
       "  0.5092138051986694,\n",
       "  0.5092037320137024,\n",
       "  0.5092136859893799,\n",
       "  0.5092136263847351,\n",
       "  0.5092310905456543,\n",
       "  0.5092237591743469,\n",
       "  0.5092172622680664,\n",
       "  0.5092132687568665,\n",
       "  0.5092167854309082,\n",
       "  0.5092166662216187,\n",
       "  0.5092067718505859,\n",
       "  0.5092270374298096,\n",
       "  0.509200930595398,\n",
       "  0.5092158317565918,\n",
       "  0.509204626083374,\n",
       "  0.50921231508255,\n",
       "  0.5092193484306335,\n",
       "  0.5092251300811768,\n",
       "  0.5092117786407471,\n",
       "  0.5092046856880188,\n",
       "  0.5092282295227051,\n",
       "  0.5092102885246277,\n",
       "  0.509218156337738,\n",
       "  0.5092142224311829,\n",
       "  0.5092109441757202,\n",
       "  0.5092085599899292,\n",
       "  0.5092248916625977,\n",
       "  0.5092392563819885,\n",
       "  0.5092112421989441,\n",
       "  0.5092222094535828,\n",
       "  0.5092147588729858,\n",
       "  0.5092104077339172,\n",
       "  0.5092129707336426,\n",
       "  0.5092214345932007,\n",
       "  0.5092215538024902,\n",
       "  0.5092132091522217,\n",
       "  0.5092111825942993,\n",
       "  0.5092020630836487,\n",
       "  0.5092092752456665,\n",
       "  0.5092329382896423,\n",
       "  0.5092210173606873,\n",
       "  0.5092054605484009,\n",
       "  0.5092343688011169,\n",
       "  0.5092160105705261,\n",
       "  0.5092162489891052,\n",
       "  0.509235143661499,\n",
       "  0.509204626083374,\n",
       "  0.5092084407806396,\n",
       "  0.5092164874076843,\n",
       "  0.5092082619667053,\n",
       "  0.5092287659645081,\n",
       "  0.5092121958732605,\n",
       "  0.5092196464538574,\n",
       "  0.5092462301254272,\n",
       "  0.5092263221740723,\n",
       "  0.5092275142669678,\n",
       "  0.5092547535896301,\n",
       "  0.5092144012451172,\n",
       "  0.5092190504074097,\n",
       "  0.5092067122459412,\n",
       "  0.5092179775238037,\n",
       "  0.5092196464538574,\n",
       "  0.5092214345932007,\n",
       "  0.5092085003852844,\n",
       "  0.5092159509658813,\n",
       "  0.5092532634735107,\n",
       "  0.5092175006866455,\n",
       "  0.5092191696166992,\n",
       "  0.5092270970344543,\n",
       "  0.5092090964317322,\n",
       "  0.5092084407806396,\n",
       "  0.509221613407135,\n",
       "  0.5092130303382874,\n",
       "  0.5092165470123291],\n",
       " 'accuracy': [0.6195312738418579,\n",
       "  0.7928125262260437,\n",
       "  0.7934374809265137,\n",
       "  0.79296875,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7932812571525574,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7932812571525574,\n",
       "  0.7934374809265137,\n",
       "  0.7932812571525574,\n",
       "  0.7932812571525574,\n",
       "  0.7935937643051147,\n",
       "  0.7931249737739563,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7931249737739563,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7935937643051147,\n",
       "  0.7932812571525574,\n",
       "  0.7931249737739563,\n",
       "  0.7932812571525574,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7934374809265137,\n",
       "  0.7935937643051147,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7934374809265137,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7934374809265137,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7935937643051147,\n",
       "  0.7932812571525574,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137,\n",
       "  0.7934374809265137],\n",
       " 'val_loss': [1.866118311882019,\n",
       "  0.6204981803894043,\n",
       "  0.5827381014823914,\n",
       "  0.5602638125419617,\n",
       "  0.5406894087791443,\n",
       "  0.5300633907318115,\n",
       "  0.5197541117668152,\n",
       "  0.5133622884750366,\n",
       "  0.5104320049285889,\n",
       "  0.5065069198608398,\n",
       "  0.5055914521217346,\n",
       "  0.5087032914161682,\n",
       "  0.5045728087425232,\n",
       "  0.5033779740333557,\n",
       "  0.5030127167701721,\n",
       "  0.502554178237915,\n",
       "  0.5023260712623596,\n",
       "  0.5036428570747375,\n",
       "  0.503527045249939,\n",
       "  0.5038087964057922,\n",
       "  0.5023847818374634,\n",
       "  0.5021255016326904,\n",
       "  0.5021894574165344,\n",
       "  0.5037553906440735,\n",
       "  0.5034511685371399,\n",
       "  0.5036150217056274,\n",
       "  0.5123185515403748,\n",
       "  0.5019421577453613,\n",
       "  0.5021069049835205,\n",
       "  0.5019710063934326,\n",
       "  0.5057740807533264,\n",
       "  0.5021498203277588,\n",
       "  0.5018052458763123,\n",
       "  0.5016486644744873,\n",
       "  0.5022922158241272,\n",
       "  0.5024911165237427,\n",
       "  0.5062937140464783,\n",
       "  0.502970814704895,\n",
       "  0.5028913021087646,\n",
       "  0.502697765827179,\n",
       "  0.5048084855079651,\n",
       "  0.5034563541412354,\n",
       "  0.5025883913040161,\n",
       "  0.5017217397689819,\n",
       "  0.5026258230209351,\n",
       "  0.5030905604362488,\n",
       "  0.5044951438903809,\n",
       "  0.5029625296592712,\n",
       "  0.5049437880516052,\n",
       "  0.5020285844802856,\n",
       "  0.5097283124923706,\n",
       "  0.5088808536529541,\n",
       "  0.5075711011886597,\n",
       "  0.5064519047737122,\n",
       "  0.5059199333190918,\n",
       "  0.5056290626525879,\n",
       "  0.5061253309249878,\n",
       "  0.5055661201477051,\n",
       "  0.5058320760726929,\n",
       "  0.5058770775794983,\n",
       "  0.5057671070098877,\n",
       "  0.5053245425224304,\n",
       "  0.5061470866203308,\n",
       "  0.5066583752632141,\n",
       "  0.5080163478851318,\n",
       "  0.505959153175354,\n",
       "  0.5065559148788452,\n",
       "  0.5050943493843079,\n",
       "  0.5096991658210754,\n",
       "  0.5088077783584595,\n",
       "  0.5069299936294556,\n",
       "  0.5095276832580566,\n",
       "  0.505321204662323,\n",
       "  0.509013831615448,\n",
       "  0.5074484348297119,\n",
       "  0.5053349137306213,\n",
       "  0.5061640739440918,\n",
       "  0.5034499764442444,\n",
       "  0.505540132522583,\n",
       "  0.5068811178207397,\n",
       "  0.5054565668106079,\n",
       "  0.5073608160018921,\n",
       "  0.505000114440918,\n",
       "  0.5054967999458313,\n",
       "  0.5070407390594482,\n",
       "  0.5109947323799133,\n",
       "  0.5114021897315979,\n",
       "  0.5144227743148804,\n",
       "  0.5047390460968018,\n",
       "  0.5046982169151306,\n",
       "  0.5046488046646118,\n",
       "  0.5045916438102722,\n",
       "  0.5045459270477295,\n",
       "  0.5044989585876465,\n",
       "  0.5044405460357666,\n",
       "  0.5044040083885193,\n",
       "  0.5043419003486633,\n",
       "  0.5042864084243774,\n",
       "  0.5042369961738586,\n",
       "  0.5041977167129517,\n",
       "  0.5041386485099792,\n",
       "  0.5040990710258484,\n",
       "  0.504051923751831,\n",
       "  0.5039951801300049,\n",
       "  0.5039610266685486,\n",
       "  0.5039205551147461,\n",
       "  0.5038709044456482,\n",
       "  0.5038198232650757,\n",
       "  0.5037925243377686,\n",
       "  0.5037431120872498,\n",
       "  0.5037103891372681,\n",
       "  0.503669798374176,\n",
       "  0.5036702752113342,\n",
       "  0.5036479830741882,\n",
       "  0.5035830736160278,\n",
       "  0.5035524964332581,\n",
       "  0.5035192966461182,\n",
       "  0.5035033226013184,\n",
       "  0.503506064414978,\n",
       "  0.503487765789032,\n",
       "  0.5034686326980591,\n",
       "  0.503447949886322,\n",
       "  0.5034707188606262,\n",
       "  0.5034340023994446,\n",
       "  0.5034259557723999,\n",
       "  0.5034312605857849,\n",
       "  0.5034017562866211,\n",
       "  0.5034118890762329,\n",
       "  0.5033770203590393,\n",
       "  0.5034121870994568,\n",
       "  0.5034024715423584,\n",
       "  0.503387451171875,\n",
       "  0.5033835172653198,\n",
       "  0.5033544301986694,\n",
       "  0.5033586621284485,\n",
       "  0.5033673644065857,\n",
       "  0.5033707618713379,\n",
       "  0.5033794641494751,\n",
       "  0.5033609867095947,\n",
       "  0.5033485889434814,\n",
       "  0.5033501386642456,\n",
       "  0.5033501982688904,\n",
       "  0.5033327341079712,\n",
       "  0.5033380389213562,\n",
       "  0.5032927989959717,\n",
       "  0.5032235980033875,\n",
       "  0.5031837821006775,\n",
       "  0.5031235814094543,\n",
       "  0.5031147599220276,\n",
       "  0.5030791759490967,\n",
       "  0.5030444264411926,\n",
       "  0.5030259490013123,\n",
       "  0.5030061602592468,\n",
       "  0.5029798746109009,\n",
       "  0.5029421448707581,\n",
       "  0.5029200911521912,\n",
       "  0.50290846824646,\n",
       "  0.5028970837593079,\n",
       "  0.5028424263000488,\n",
       "  0.5028569102287292,\n",
       "  0.5028170347213745,\n",
       "  0.5028102397918701,\n",
       "  0.5027644634246826,\n",
       "  0.5027552247047424,\n",
       "  0.5027198195457458,\n",
       "  0.502686619758606,\n",
       "  0.5026715397834778,\n",
       "  0.5026615262031555,\n",
       "  0.5026231408119202,\n",
       "  0.5026105046272278,\n",
       "  0.502587080001831,\n",
       "  0.5025772452354431,\n",
       "  0.5025478005409241,\n",
       "  0.5025575160980225,\n",
       "  0.5025231838226318,\n",
       "  0.5024812817573547,\n",
       "  0.5024626851081848,\n",
       "  0.5024622082710266,\n",
       "  0.5024440884590149,\n",
       "  0.5024228096008301,\n",
       "  0.5023689270019531,\n",
       "  0.5023490786552429,\n",
       "  0.5023525357246399,\n",
       "  0.5022920370101929,\n",
       "  0.5022706985473633,\n",
       "  0.5022339820861816,\n",
       "  0.5022208094596863,\n",
       "  0.5021678805351257,\n",
       "  0.5021323561668396,\n",
       "  0.5020952820777893,\n",
       "  0.5020842552185059,\n",
       "  0.5020678043365479,\n",
       "  0.5020512938499451,\n",
       "  0.5019997954368591,\n",
       "  0.5020098686218262,\n",
       "  0.5020087957382202,\n",
       "  0.5019819140434265,\n",
       "  0.5019873976707458,\n",
       "  0.5019864439964294,\n",
       "  0.5019989609718323],\n",
       " 'val_accuracy': [0.7950000166893005,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7981250286102295,\n",
       "  0.796875,\n",
       "  0.7987499833106995,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.7962499856948853,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.796875,\n",
       "  0.7981250286102295,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7981250286102295,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7987499833106995,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.7987499833106995,\n",
       "  0.7962499856948853,\n",
       "  0.7962499856948853,\n",
       "  0.7962499856948853,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7962499856948853,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7962499856948853,\n",
       "  0.7975000143051147,\n",
       "  0.7962499856948853,\n",
       "  0.796875,\n",
       "  0.7981250286102295,\n",
       "  0.796875,\n",
       "  0.7981250286102295,\n",
       "  0.7975000143051147,\n",
       "  0.796875,\n",
       "  0.7975000143051147,\n",
       "  0.7962499856948853,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7975000143051147,\n",
       "  0.7962499856948853,\n",
       "  0.7962499856948853,\n",
       "  0.7962499856948853,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7975000143051147,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7981250286102295,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995,\n",
       "  0.7987499833106995]}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f0a36d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "729e0b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9819e17640>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2506726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83005fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ed05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1d1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
