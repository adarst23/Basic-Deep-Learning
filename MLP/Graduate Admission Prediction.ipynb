{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3b8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a875afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef2024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86becfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f418026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a1e3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Serial No.',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57345500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9e9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Chance of Admit ', axis=1)\n",
    "y = df['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bb16a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12452a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f222f0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19eb5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9227f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb4907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe22795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ad579a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7,activation='relu', input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec174739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "229fc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "308f3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.8984 - val_loss: 0.8961\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7475 - val_loss: 0.7370\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6052 - val_loss: 0.5989\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4957 - val_loss: 0.4938\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4061 - val_loss: 0.4036\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3304 - val_loss: 0.3214\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2606 - val_loss: 0.2497\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2010 - val_loss: 0.1871\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1481 - val_loss: 0.1348\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1041 - val_loss: 0.0913\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0679 - val_loss: 0.0570\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0318\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0167\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0067\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0063\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0059\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0044\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled,y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b7e3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68ccc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c7e707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765941149773281"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f884c1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f65dc669550>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57d129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
